<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Estimating Accuracy from Unlabeled Data A Probabilistic Logic Approach]]></title>
    <url>%2F2017%2F11%2F15%2Festi-accur-psl%2F</url>
    <content type="text"><![CDATA[MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); IntroductionBackgroundEstimating the accuracy of classifiers is central to machine learning and many other ﬁelds. Most existing approaches to eastimating accuracy are supervised, meaning that a set of labeled examples is required for the Estimation. However, being able to estimate the accuracies of classifiers using only Unlabeled data is very important for many applications. Futhermore, tasks which involve making several predictions which are tied together by logical constraints are abundant in machine learning. IntuitionMutual ExclusionIf domains d1 and d2 are mutually exclusive,then $f^{d_1} =1$ implies that $f^{d_2} =0$.For example, in the NELL setting, if a NP belongs to the “city” category,then it cannot also belong to the “animal” category. Subsumption For example, in the NELL setting, if a NP belongs to the “cat” category, then it must also belong to the “animal” category. Proposed MethedDefine a set of Logic Rules(i) defining a set of logic rules for modeling the logical constraints between the $f^d$ and the $\hat{f}^d_j$ ,in terms of the error rates $e^d_j$ and the known logical constraints. Probabilistic LogicIn classical logic, we have a set of predicates (e.g., mammal(x) indicating whether x is a mammal, where x is a variable) and a set of rules deﬁned in terms of these predicates. These ground predicates and rules take boolean values. In probabilistic logic, we are instead interested in inferring the probabilities of these ground predicates and rules being true, given a set of observed ground predicates and rules.Furthermore, the truth values of ground predicates and rules may be continuous and lie in the interval [0,1], instead of being boolean,representing the probability that the corresponding ground predicate or rule is true. Model Function Approximation Outputs: $\hat{f}^d_j(X),j=1,…,N^d, inputs X\in \chi$ Target Function Outputs: $f^d(X),inputs X\in \chi$ Function Approximation Error Rates: $e^d_j,j=1,…,N^d$ Ensemble Rules$$\hat{f}^d_j(X)\land \neg e^d_j \rightarrow f^d(X),\neg \hat{f}^d_j(X)\land \neg e^d_j \rightarrow \neg f^d(X)$$$$\hat{f}^d_j(X)\land e^d_j \rightarrow\neg f^d(X),\neg \hat{f}^d_j(X)\land e^d_j \rightarrow f^d(X)$$ ConstraintsMutual Exclusion Rule$$ME(d_1,d_2)\land \hat{f}^{d_1}_j(X) \land f^{d_2}(X) \rightarrow e^{d_1}_j,for d_1\neq d_2=1,…,D,j=1,…,N^{d_1},and X\in \chi $$ Subsumption Rule$$SUB(d_1,d_2)\land \neg\hat{f}^{d_1}_j(X) \land f^{d_2}(X) \rightarrow e^{d_1}_j,for d_1=d_2=1,…,D,j=1,…,N^{d_1},and X\in \chi$$ Perform probabilistic inference(ii) performing probabilistic inference using these rules as priors,in order to obtain the most likely values of the $e^d_j$ and the $f^d$,which are not observed. Probabilistic Soft Logic (PSL)Define the terms: The unobserved ground predicate values: $\boldsymbol{Y}={Y_1,…,Y_m},Domain \boldsymbol{D}=[0,1]^m$. Observed ground predicate values: $\boldsymbol{X}={X_1,…,X_m},Domain \boldsymbol{D}=[0,1]^n$. Continuous potential functions: $\phi={\phi_1,…,\phi_k}$,$\phi_j(\boldsymbol{X},\boldsymbol{Y})=(max{\mathcal{l}_j(\boldsymbol{X},\boldsymbol{Y}),0})^{p_j}$, $\mathcal{l}_j$ is a linear functions of X and Y,$p_j\in{1,2}$. Free parameters $\lambda={\lambda_1,…,\lambda_k}$ Define HL-MRF Density:$$f(\boldsymbol{Y})=\frac{1}{Z}exp(-\Sigma^k_{j=1}\lambda_j\phi_j(X,Y))$$]]></content>
      <categories>
        <category>paper_read</category>
      </categories>
      <tags>
        <tag>logic</tag>
        <tag>Unlabeled_Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Course_notes for cse547 —— number_theory]]></title>
    <url>%2F2017%2F11%2F12%2Fnumber-theory%2F</url>
    <content type="text"><![CDATA[MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); DivisibilityPrimesPrime examplesFactorial Factorsrelative primeMOD: the congruence relationIndependent ResidueAdditional Applications$$ \varphi &amp; \mu$$]]></content>
      <categories>
        <category>concrete_mathematics</category>
        <category>course_notes</category>
      </categories>
      <tags>
        <tag>number_theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[progressive_gan]]></title>
    <url>%2F2017%2F11%2F07%2Fprogressive-gan%2F</url>
    <content type="text"><![CDATA[ContributionsPrimary contribution: Propose a training methodology for GANs where start with low-resolution images, and then progressively increase the resolution by adding layers to the networks. Others: Increasing variation using minibatch standard deviation A new normalization in G and D Propose sliced Wasserstein distance (SWD) to estimate the statistical similarity. progressive training Training frame Transition from 16x16 to 32x32 Benefits of progressive TrainingMore Stable: Early on, the generation of smaller images is substantially more stable because there is less class information and fewer modes. By increasing the resolution little by little we are continuously asking a much simpler question compared to the end goal of discovering a mapping from latent vectors. The reduced training time: With progressively growing GANs most of the iterations are done at lower resolutions, and comparable result quality is often obtained up to 2–6 times faster, depending on the ﬁnal output resolution. sliced Wasserstein distanceMotivation The previous methods like MS-SSIM do not directly assess image quality in terms of similarity to the training set. Therefore, they propose a new metric sliced Wasserstein distance which will measure the distance between training set and generated samples. Experiments Convergence and Training speed ExperimentsCeleb High quality lsun CIFAR10]]></content>
      <categories>
        <category>deeplearning</category>
        <category>paper_read</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tree-RL for object localization]]></title>
    <url>%2F2017%2F11%2F01%2FTree-RL-md%2F</url>
    <content type="text"><![CDATA[Motivation:current methods:Most of current object detection methods only use local image patch independently. However, the critical correlation cues among different proposals (e.g., relative spatial layouts or semantic correlations) are often ignored. Reinforcement LearningIn this paper, in order to exploit global interdependency among objects, they propose a Tree-RL approach that learns to localize multiple objects sequentially based on both the current observation and historical search paths. Reinforcement Learnin Recall To form a reinforcement learning frame, We need to define 3 components:ActionStateReward Definition of Actions There are 13 actions being divided into two group. The first group include 5 scaling actions, the second include 8 local translation actions. Definition of StateStates: concatenation of three components: 1.the feature vector of the current window, 2.the feature vector of the whole image 3.the history of taken actions. Definition of Reward Notes: 1.The first key reward stimulation +5 is given to those actions which cover any ground-truth objects with an IoU greater than 0.5 for the ﬁrst time. (The f is defined that when IoU(w,g)&gt;0.5, f=+1; otherwise f=-1.) 2.The second item means if the next window’s IoU(w’,g) is bigger than current’s IoU(w,g), r=+1, which means the window get closer to the ground truth; otherwise r=-1. Tree Structured Search This is the most different point with previous paper about rl for object detection.The Agent in this paper will select a best actions from two action group. The left is scaling action, the right is local translation action.And they will set the max level of the tree. For example, when setting the level equals to 4, there will be 15 proposals in the tree. And then these proposals will be put into a final classifier, which is similar to other proposal method. ExperimentsVisualization Recall Comparison to Other Object Proposal Algorithms Detection mAP Comparison to Faster R-CNN Here, they combined Tree_RL as proposal method with Fast RCNN to get the detection results.And they compare it with RPN + Fast RCNN and Faster RCNN method. We can see this paper score better than RPN but close to Faster R-CNN. But we should consider that Tree-RL only use a VGG-16 because of the limitation of computation.]]></content>
      <categories>
        <category>deeplearning</category>
        <category>Object_Detection</category>
        <category>paper_read</category>
      </categories>
      <tags>
        <tag>Reinforcement_Leearning</tag>
        <tag>Object_Detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Conclusion for Generative Adversarial Networks]]></title>
    <url>%2F2017%2F10%2F28%2FGAN_conclusion%2F</url>
    <content type="text"><![CDATA[MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); Overview GAN DCGAN CGAN improv GAN LapGAN info-GAN WGAN 1. GANThe basic GAN model was proposed by Ian Goodfellow in 2014.This model include 2 Parts: generative model and discriminate model: Generative modelThe generative model intend to produce the sample close to real sample. Discriminate modelThe discriminator intend to improve the ability to judge whether the sample is real.]]></content>
      <categories>
        <category>deeplearning</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程入门]]></title>
    <url>%2F2017%2F04%2F19%2Fprogramming%2F</url>
    <content type="text"><![CDATA[编程入门编程语言定义编程语言是用来定义计算机程序的形式语言。它是一种被标准化的交流技巧，用来向计算机发出指令。一种计算机语言让程序员能够准确地定义计算机所需要使用的数据，并精确地定义在不同情况下所应当采取的行动。 什么是编程编程语言是具有不同层次的，有机器语言，汇编语言，高级语言。要理解编程语言的层次，我们要从什么是编程说起。从上面对编程语言的定义来看，我们可以简单的把编程理解为人与机器交流的语言。可是人类和机器接受语言的形式是不一样的。 对于人类来说，语言是由词汇组成的语句段落，词汇（或者说构成词汇的字母）是人类语言的基本单元，词汇组合在一起从而传达信息。 对于机器而言，能够接受的语言形式则是0,1字符串(从硬件上来看就是电位的高低与否)，总之机器的语言便是0,1串，如0111101111对于机器而言可能代表了一定的指令信息。 那么编程所要做的事情就是把人类交流的语言和机器的语言联系起来。然而很不幸的事情是人类通用的语言逻辑过于复杂且充满了模糊性，这是目前的计算机技术所无法实现的。而编程语言正是为了解决这个问题所诞生的一种语言，我们通过设计特殊的语法，使得编程语言不在像我们日常使用的语言一样复杂且模糊，使得它更加接近计算机所能接受的逻辑。这是从目的上来理解编程语言。就是为了让计算机听的懂人话。 当然我们也可以从另一个角度来理解，机器语言由0，1串构成，对于人类来说简直难以忍受，试想如果我们都用01串来沟通交流，那是多么可怕的一件事情。然而事实上，最早的编程人员就是用机器语言来编程，那个时候的计算机还是使用晶体管(总之就是比较low)，他们会制作一堆插线孔，插上了就代表1，没有插上就代表0。所谓编程对他们来说就是插上成千上万根线，有一根线插错了也不行。这也就是为什么老一辈的人都认为电脑是一个特别难的东西，大概是当初留下了心理阴影。 正是因为机器语言这么麻烦，早年的程序员们自然就受不了了。为了方便自己方便后人，他们就发明了汇编语言。这个汇编语言说白了就是把01串用人话表示出来。汇编语言其实就是一个个简单的字母指令串，它包含了人们通常会让计算机做的指令，比如加(add)，减(minus)，还有变换地址等。从此程序员们就告别了使用插线板编程的苦逼的时代。人们开始通过汇编语言的指令串来指挥计算机，而机器内部又自有一套对应关系将这个指令集转变为机器语言让计算机读懂。 然而，汇编语言虽然相对于机器语言非常简单，但其实仍然特别麻烦，至少我是没有完全学会的。。。所以，伟大的程序员先驱们有创造了更加简单的语言，也就是LISP,Fortran,C,C++等高级语言。这些高级编程语言对于我们人类来说就更为友好了，至少比一大堆01串或者指令集友好的多吧。 但是这些高级语言们虽然对人类友好了，可是机器读不懂啊，所以就需要有一个翻译官来把高级语言先翻译成汇编语言。我们把这种翻译的过程叫做编译，把这个翻译官叫做编译器。(当然这个编译器本身其实也是一个程序了，以至于我曾经一直在想第一个编译器是用什么编译的，大概是某个大佬不辞辛劳的用汇编语言写了一个编译器吧，感谢大佬！当然对于大部分的coder来说是不需要知道编译器是怎么做的，用别人做好的就可以了。。) 什么是C语言首先C语言是一门高级编程语言，至于为什么高级当然是和汇编语言和机器语言来比了。 其次C语言是一门面向过程的语言，至于什么叫面向过程又不得不提面向对象吧，提到面向对象又不得不提C++,java等语言了。作为一个嫌麻烦的人还是先不解释吧，等后面提面向对象的时候再说。当然这个也可以自己先脑补一下，有助于脑洞开发。 编译器配置新手上路作为一个新手而言呢，其实编译器有两种选择。 第一种选择是自己配置 编辑器 + 编译器 的组合比较能够锻炼你的编程能力，当然也不好说，现在各种编程工具也是厉害，能用的好也是殊途同归。至于常用的编辑器有 Atom, Sublime text, notepad++,vim,emacs等，当然原则上你用记事本写也是可以的。对于编译器最常用的就是gcc了。具体使用方法就视编辑器不同了。 第二种选择是使用特定的IDE(集成开发环境，Integrated Development Environment)，通常来说使用简单，功能强大。作为一个windows用户，我自己最早用的是Visual Studio。功能强大，而且是微软自己家的，有庞大的技术支持。但是缺点就是其他系统用不了，而且比较大，功能太过齐全很多组件用不上。 Visual Studio的安装和使用参考教程 注意visual C++中包含了C语言。 学习资料菜鸟教程imooc教程 参考资料维基百科:C语言 维基百科:编程语言]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>programming</tag>
        <tag>introduction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN overview]]></title>
    <url>%2F2017%2F03%2F13%2FGAN_overview%2F</url>
    <content type="text"><![CDATA[MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); 从生成模型到生成对抗网络1. 生成模型与判别模型主流的深度学习算法分为两种: 生成模型和判别模型。其中： (1) 生成模型:对联合分布 P(X,Y)进行建模。 X为输入，Y为输出或者隐含层。 直观来讲，我们认为 输入的数据X和输出的标签或者回归值Y合并的变量构成一个分布P(X,Y)。而我们所有的训练样本 (X,Y)均是由这个分布生成。对于生成模型的目的，就是学习到这样一个分布，也可以说是(X,Y)的联合分布。生成模型可以得到模型中任何一个变量的值。 (2) 判别模型：直接对 Y=f(X)或者 P(Y|X)建模。 而对于判别模型，我们认为输入数据 X 和输出值 Y构成函数关系，而判别模型的任务就是学习直接学习到这个函数关系，从而直接由输入X估计输出值Y。判别模型只能再给定输入的情况下得到输出的值。 2. 生成模型的基本概念(1) 生成模型中最基本的概念就是数据样本的分布。利用这个分布我们可以生成数据样本，也可以利用条件概率的方法得到一个条件概率密度函数来做统计推断。 (2) 统计推断在生成模型的方法中，我们常常要利用数据样本的分布来进行推断。通常的方法是利用条件概率公式: $$p(Y|X) = \frac{p(X,Y)}{p(X)}$$ 而P(X)在通常的模型中被作为一个归一化因子。所以需要求的模型就是 P(X,Y).只要得到了 P(X,Y)，我们就可以很轻易的推断出P(Y|X). (3) 生成模型中的基本模型 Wikipedia Gaussian mixture model Hidden Markov model Probabilistic context-free grammar Naive Bayes Averaged one-dependence estimators Latent Dirichlet allocation Restricted Boltzmann machine Generative adversarial networks 2.生成对抗网络基本概念生成对抗网络在2014年被Ian Goodfellow所提出。]]></content>
      <categories>
        <category>deeplearning</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow learning]]></title>
    <url>%2F2017%2F03%2F08%2Ftensorflow_learning%2F</url>
    <content type="text"><![CDATA[tensorflow learningPart 1: Prepare dataThis is common for all deep learning work. And it depends on the data. In python, many people like to use pickle to store data. import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;,one_hot = True) In general, data include inputs and labels. Part 2: build modelAt most time, we could create a python file named model.py to define our deep learning model. In general, the model include the input layers, hidden layers and loss function. We use placeholder to set the input layers in tensorflow. (Take mnist as example) inputs = tf.placeholder(dtype=&apos;float32&apos;,shape=[None,784],name=&apos;inputs&apos;) labels = tf.placeholder(dtype=&apos;float32&apos;,shape=[None,10],name=&apos;labels&apos;) And we define every layers by the code below: in_size = 784 hid_size = 10 with tf.name_scope(&apos;layer1&apos;): Weights= tf.Variable(tf.random_normal([in_size,hid_size]),name=&apos;Weights&apos;) biases = tf.Variable(tf.random_normal(1,hid_size),name = &apos;biases&apos;) l1 = tf.add(tf.matmul(inputs,Weights),biases) define loss: loss = tf.loss.mean_square(l1,labels) define summary: tf.summary.scalar(loss,name=&apos;loss&apos;) Part 3: train and savedefine the training sizebatch_size = 100all_size = 50000 define the Sessionwith tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: initialize the parameterstf.global_variables_initializer().run() merged = tf.summary.merge_all() train_writer = tf.summary.FileWriter(&apos;logs/&apos;,sess.graph) for epoch in range(1000): begin = epoch*batch_size%(all_size-batch_size) end = begin + batch_size batch = inputs[begin:end] print(batch.shape) batch_labels = labels[epoch*batch_size:(epoch+1) * batch_size] input the training data train_summary,loss_value=sess.run([train_step,loss],feed_dict={image_inputs:batch,points:batch_labels}) if (epoch%10==0): train_writer.add_summary(train_summary,epoch) print(loss_value) train_writer.close()]]></content>
      <categories>
        <category>deeplearning_frame</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
</search>
